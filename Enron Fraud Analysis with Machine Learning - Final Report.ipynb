{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Scandal: The smartest guys in the room?\n",
    "\n",
    "## Author: Sagarnil Das\n",
    "## Date: 28th June, 2017\n",
    "\n",
    "Enron, a multibillion dollar company in the heart of the Wall Street was one of the largest companies in the United States in 2000. By 2002, it collapsed into bankruptcy due to widespread corporate fraud. They reached a dizzying height only to face a plummeting collapse. The bankruptcy of Enron affected thousands of its employees and shook the whole Wall Street by its foundation. In the federal investigation that followed, all the emails from Enron employees were made public. Since then these emails have spreaded like a wildfire through the world and many analysis and investigations have been done on this data. In this project, my target is to build a ** Person of Interest ** identifier/Label and try to build a Machine Learning Algorithm to predict the possible Persons of Interest based on various features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?\n",
    "\n",
    "The goal of this project was to utilize the financial and email data from Enron to build a predictive, analytic model that could identify whether an individual could be considered a \"person of interest\" (POI). Since the dataset contained labeled data--culpable persons were already listed as POIs--the value of this model on the existing dataset is limited. Rather, the potential value such a model may provide is in application to other datasets from other companies, to potentially identify suspects worth investigating further. The dataset contained 146 records with 14 financial features, 6 email features, and 1 labeled feature (POI). Of the 146 records, 18 were labeled, a priori, as persons of interest. Through exploratory data analysis and cursory spreadsheet/CSV review, I was able to identify 2 candidate records for removal:\n",
    "\n",
    "TOTAL: This was an extreme outlier for most numerical features, as it was likely a spreadsheet artifact.\n",
    "THE TRAVEL AGENCY IN THE PARK: This record did not represent an individual.\n",
    "After data cleaning, 144 records remained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Preparation/Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features list and Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\n",
    "                 'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person',\n",
    "                 'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 5600000,\n",
      " 'deferral_payments': 'NaN',\n",
      " 'deferred_income': 'NaN',\n",
      " 'director_fees': 'NaN',\n",
      " 'email_address': 'jeff.skilling@enron.com',\n",
      " 'exercised_stock_options': 19250000,\n",
      " 'expenses': 29336,\n",
      " 'from_messages': 108,\n",
      " 'from_poi_to_this_person': 88,\n",
      " 'from_this_person_to_poi': 30,\n",
      " 'loan_advances': 'NaN',\n",
      " 'long_term_incentive': 1920000,\n",
      " 'other': 22122,\n",
      " 'poi': True,\n",
      " 'restricted_stock': 6843672,\n",
      " 'restricted_stock_deferred': 'NaN',\n",
      " 'salary': 1111258,\n",
      " 'shared_receipt_with_poi': 2042,\n",
      " 'to_messages': 3627,\n",
      " 'total_payments': 8682716,\n",
      " 'total_stock_value': 26093672}\n",
      "Total number of people in the dataset: 146\n",
      "Total number of features in the dataset: 21\n",
      "Number of POIs in the dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#Sample data for one of the Top executives - Jeffrey Skilling\n",
    "pprint.pprint(data_dict[\"SKILLING JEFFREY K\"])\n",
    "\n",
    "#Number of people in the datasets\n",
    "\n",
    "print \"Total number of people in the dataset: \" + str(len(data_dict))\n",
    "\n",
    "#Number of features available in the dataset\n",
    "\n",
    "print \"Total number of features in the dataset: \" + str(len(data_dict[\"SKILLING JEFFREY K\"]))\n",
    "\n",
    "#Number of POIs in the dataset\n",
    "\n",
    "def poi_count(file):\n",
    "    count = 0\n",
    "    for data in file:\n",
    "        if file[data]['poi'] == True:\n",
    "            count += 1\n",
    "    print \"Number of POIs in the dataset: \" + str(count)\n",
    "\n",
    "poi_count(data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect outliers and remove them\n",
    "\n",
    "Now we will consider a few features where having outliers can significantly affect our whole analysis. We will analyze these outliers to see whether they should be there or we can remove them to make our analysis more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97343619.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqSGoSBJahgKkqSGoSBJahgKkqTG/wcR7vBM0cokogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe7eea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [\"bonus\",\"salary\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "print(data.max())\n",
    "\n",
    "for point in data:\n",
    "    bonus = point[0]\n",
    "    salary = point[1]\n",
    "    plt.scatter( bonus, salary )\n",
    "\n",
    "plt.xlabel(\"bonus\")\n",
    "plt.ylabel(\"salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW! That's a huge outlier right there in the upper right corner! In fact it is so big that it is making all the other points insignificant in scale. So what's going on over there? Looking at the dataset, we see it is an excel artifact which calculated the ** TOTAL ** value or the sum. So it should be removed. Another point which should be removed is ** THE TRAVEL AGENCY IN THE PARK **. Both of these values does not belong to any individual and thus not significant for our analysis. We also try to find out who got the maximum salary and the maximum bonus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TOTAL', 26704229), ('SKILLING JEFFREY K', 1111258)]\n"
     ]
    }
   ],
   "source": [
    "outliers_salary = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers_salary.append((key,int(val)))\n",
    "\n",
    "pprint.pprint(sorted(outliers_salary,key=lambda x:x[1],reverse=True)[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TOTAL', 97343619), ('LAVORATO JOHN J', 8000000)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "outliers_bonus = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['bonus']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers_bonus.append((key,int(val)))\n",
    "\n",
    "pprint(sorted(outliers_bonus,key=lambda x:x[1],reverse=True)[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats's some insane amount of money right there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Total and Travel Agency in the Park outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('TOTAL',0)\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting after outlier removal\n",
    "\n",
    "We will try to plot the same plot. Now that we have removed the huge outliers, we should expect to see something much different than what we saw before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEKCAYAAABdWiGrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf222ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_dataset = data_dict\n",
    "my_feature_list = features_list\n",
    "data = featureFormat(data_dict, features)\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter( salary, bonus )\n",
    "\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating emails from and to a Person of Interest\n",
    "\n",
    "Now we will investigate from_this_person_to_poi and from_poi_to_this_person for any outliers as they are important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAELCAYAAAAspXpuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJMzMLCsnCTMzy8pJwszMsvr/AXmGXmq71dT2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe561cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [\"from_this_person_to_poi\", \"from_poi_to_this_person\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "print data.max()\n",
    "#Plotting the graph\n",
    "for point in data:\n",
    "    from_this_person_to_poi = point[0]\n",
    "    from_poi_to_this_person = point[1]\n",
    "    plt.scatter( from_this_person_to_poi, from_poi_to_this_person )\n",
    "\n",
    "plt.xlabel(\"from_this_person_to_poi\")\n",
    "plt.ylabel(\"from_poi_to_this_person\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a few outliers. But on investigation, I found out that they are real persons and not data error. So I am going to keep them in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with 'NaN' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonus                         63\n",
      "deferral_payments            106\n",
      "deferred_income               96\n",
      "director_fees                128\n",
      "email_address                 33\n",
      "exercised_stock_options       43\n",
      "expenses                      50\n",
      "from_messages                 58\n",
      "from_poi_to_this_person       58\n",
      "from_this_person_to_poi       58\n",
      "loan_advances                141\n",
      "long_term_incentive           79\n",
      "other                         53\n",
      "poi                            0\n",
      "restricted_stock              35\n",
      "restricted_stock_deferred    127\n",
      "salary                        50\n",
      "shared_receipt_with_poi       58\n",
      "to_messages                   58\n",
      "total_payments                21\n",
      "total_stock_value             19\n",
      "dtype: int64\n",
      "(144, 21)\n",
      "bonus                        0\n",
      "deferral_payments            0\n",
      "deferred_income              0\n",
      "director_fees                0\n",
      "email_address                0\n",
      "exercised_stock_options      0\n",
      "expenses                     0\n",
      "from_messages                0\n",
      "from_poi_to_this_person      0\n",
      "from_this_person_to_poi      0\n",
      "loan_advances                0\n",
      "long_term_incentive          0\n",
      "other                        0\n",
      "poi                          0\n",
      "restricted_stock             0\n",
      "restricted_stock_deferred    0\n",
      "salary                       0\n",
      "shared_receipt_with_poi      0\n",
      "to_messages                  0\n",
      "total_payments               0\n",
      "total_stock_value            0\n",
      "dtype: int64\n",
      "       bonus  deferral_payments  deferred_income  director_fees  \\\n",
      "0   600000.0                0.0              0.0            0.0   \n",
      "1  1200000.0          1295738.0       -1386055.0            0.0   \n",
      "2   350000.0                0.0        -400729.0            0.0   \n",
      "3        0.0                0.0              0.0            0.0   \n",
      "4  1500000.0                0.0       -3117011.0            0.0   \n",
      "\n",
      "              email_address  exercised_stock_options  expenses  from_messages  \\\n",
      "0      mark.metts@enron.com                      0.0   94299.0           29.0   \n",
      "1                         0                6680544.0   11200.0            0.0   \n",
      "2  steven.elliott@enron.com                4890344.0   78552.0            0.0   \n",
      "3     bill.cordes@enron.com                 651850.0       0.0           12.0   \n",
      "4    kevin.hannon@enron.com                5538001.0   34039.0           32.0   \n",
      "\n",
      "   from_poi_to_this_person  from_this_person_to_poi        ...          \\\n",
      "0                     38.0                      1.0        ...           \n",
      "1                      0.0                      0.0        ...           \n",
      "2                      0.0                      0.0        ...           \n",
      "3                     10.0                      0.0        ...           \n",
      "4                     32.0                     21.0        ...           \n",
      "\n",
      "   long_term_incentive      other    poi  restricted_stock  \\\n",
      "0                  0.0     1740.0  False          585062.0   \n",
      "1            1586055.0  2660303.0  False         3942714.0   \n",
      "2                  0.0    12961.0  False         1788391.0   \n",
      "3                  0.0        0.0  False          386335.0   \n",
      "4            1617011.0    11350.0   True          853064.0   \n",
      "\n",
      "   restricted_stock_deferred    salary  shared_receipt_with_poi  to_messages  \\\n",
      "0                        0.0  365788.0                    702.0        807.0   \n",
      "1                        0.0  267102.0                      0.0          0.0   \n",
      "2                        0.0  170941.0                      0.0          0.0   \n",
      "3                        0.0       0.0                     58.0        764.0   \n",
      "4                        0.0  243293.0                   1035.0       1045.0   \n",
      "\n",
      "   total_payments  total_stock_value  \n",
      "0       1061827.0           585062.0  \n",
      "1       5634343.0         10623258.0  \n",
      "2        211725.0          6678735.0  \n",
      "3             0.0          1038185.0  \n",
      "4        288682.0          6391065.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.759974e+05</td>\n",
       "      <td>2.220896e+05</td>\n",
       "      <td>-1.936833e+05</td>\n",
       "      <td>9980.319444</td>\n",
       "      <td>2.075802e+06</td>\n",
       "      <td>35375.340278</td>\n",
       "      <td>363.583333</td>\n",
       "      <td>38.756944</td>\n",
       "      <td>24.625000</td>\n",
       "      <td>5.828125e+05</td>\n",
       "      <td>3.369578e+05</td>\n",
       "      <td>2.947455e+05</td>\n",
       "      <td>8.685363e+05</td>\n",
       "      <td>7.341790e+04</td>\n",
       "      <td>1.854460e+05</td>\n",
       "      <td>702.611111</td>\n",
       "      <td>1238.555556</td>\n",
       "      <td>2.256543e+06</td>\n",
       "      <td>2.909786e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.233155e+06</td>\n",
       "      <td>7.541013e+05</td>\n",
       "      <td>6.060111e+05</td>\n",
       "      <td>31300.575144</td>\n",
       "      <td>4.795513e+06</td>\n",
       "      <td>45309.303038</td>\n",
       "      <td>1450.675239</td>\n",
       "      <td>74.276769</td>\n",
       "      <td>79.778266</td>\n",
       "      <td>6.794472e+06</td>\n",
       "      <td>6.871826e+05</td>\n",
       "      <td>1.131325e+06</td>\n",
       "      <td>2.016572e+06</td>\n",
       "      <td>1.301983e+06</td>\n",
       "      <td>1.970421e+05</td>\n",
       "      <td>1077.290736</td>\n",
       "      <td>2237.564816</td>\n",
       "      <td>8.847189e+06</td>\n",
       "      <td>6.189018e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-3.504386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-1.787380e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.708600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.434500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.019275e+04</td>\n",
       "      <td>2.443265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>20182.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.190000e+02</td>\n",
       "      <td>3.605280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.105960e+05</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>347.500000</td>\n",
       "      <td>9.413595e+05</td>\n",
       "      <td>9.659550e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>8.535500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.683580e+06</td>\n",
       "      <td>53328.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.745862e+05</td>\n",
       "      <td>1.485770e+05</td>\n",
       "      <td>7.374560e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.696675e+05</td>\n",
       "      <td>933.750000</td>\n",
       "      <td>1623.000000</td>\n",
       "      <td>1.945668e+06</td>\n",
       "      <td>2.295176e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>6.426990e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>137864.000000</td>\n",
       "      <td>3.434838e+07</td>\n",
       "      <td>228763.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>8.152500e+07</td>\n",
       "      <td>5.145434e+06</td>\n",
       "      <td>1.035973e+07</td>\n",
       "      <td>1.476169e+07</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>1.111258e+06</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>1.035598e+08</td>\n",
       "      <td>4.911008e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  1.440000e+02       1.440000e+02     1.440000e+02     144.000000   \n",
       "mean   6.759974e+05       2.220896e+05    -1.936833e+05    9980.319444   \n",
       "std    1.233155e+06       7.541013e+05     6.060111e+05   31300.575144   \n",
       "min    0.000000e+00      -1.025000e+05    -3.504386e+06       0.000000   \n",
       "25%    0.000000e+00       0.000000e+00    -3.708600e+04       0.000000   \n",
       "50%    3.000000e+05       0.000000e+00     0.000000e+00       0.000000   \n",
       "75%    8.000000e+05       8.535500e+03     0.000000e+00       0.000000   \n",
       "max    8.000000e+06       6.426990e+06     0.000000e+00  137864.000000   \n",
       "\n",
       "       exercised_stock_options       expenses  from_messages  \\\n",
       "count             1.440000e+02     144.000000     144.000000   \n",
       "mean              2.075802e+06   35375.340278     363.583333   \n",
       "std               4.795513e+06   45309.303038    1450.675239   \n",
       "min               0.000000e+00       0.000000       0.000000   \n",
       "25%               0.000000e+00       0.000000       0.000000   \n",
       "50%               6.082935e+05   20182.000000      17.500000   \n",
       "75%               1.683580e+06   53328.250000      53.000000   \n",
       "max               3.434838e+07  228763.000000   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "count               144.000000               144.000000   1.440000e+02   \n",
       "mean                 38.756944                24.625000   5.828125e+05   \n",
       "std                  74.276769                79.778266   6.794472e+06   \n",
       "min                   0.000000                 0.000000   0.000000e+00   \n",
       "25%                   0.000000                 0.000000   0.000000e+00   \n",
       "50%                   4.000000                 0.000000   0.000000e+00   \n",
       "75%                  41.250000                14.000000   0.000000e+00   \n",
       "max                 528.000000               609.000000   8.152500e+07   \n",
       "\n",
       "       long_term_incentive         other  restricted_stock  \\\n",
       "count         1.440000e+02  1.440000e+02      1.440000e+02   \n",
       "mean          3.369578e+05  2.947455e+05      8.685363e+05   \n",
       "std           6.871826e+05  1.131325e+06      2.016572e+06   \n",
       "min           0.000000e+00  0.000000e+00     -2.604490e+06   \n",
       "25%           0.000000e+00  0.000000e+00      2.434500e+04   \n",
       "50%           0.000000e+00  9.190000e+02      3.605280e+05   \n",
       "75%           3.745862e+05  1.485770e+05      7.374560e+05   \n",
       "max           5.145434e+06  1.035973e+07      1.476169e+07   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.440000e+02  1.440000e+02               144.000000   \n",
       "mean                7.341790e+04  1.854460e+05               702.611111   \n",
       "std                 1.301983e+06  1.970421e+05              1077.290736   \n",
       "min                -1.787380e+06  0.000000e+00                 0.000000   \n",
       "25%                 0.000000e+00  0.000000e+00                 0.000000   \n",
       "50%                 0.000000e+00  2.105960e+05               114.000000   \n",
       "75%                 0.000000e+00  2.696675e+05               933.750000   \n",
       "max                 1.545629e+07  1.111258e+06              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count    144.000000    1.440000e+02       1.440000e+02  \n",
       "mean    1238.555556    2.256543e+06       2.909786e+06  \n",
       "std     2237.564816    8.847189e+06       6.189018e+06  \n",
       "min        0.000000    0.000000e+00      -4.409300e+04  \n",
       "25%        0.000000    9.019275e+04       2.443265e+05  \n",
       "50%      347.500000    9.413595e+05       9.659550e+05  \n",
       "75%     1623.000000    1.945668e+06       2.295176e+06  \n",
       "max    15149.000000    1.035598e+08       4.911008e+07  "
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making dataframes in pandas one for the keys and one for the values\n",
    "\n",
    "df_values = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "df_values.head()\n",
    "\n",
    "df_persons = pd.Series(list(data_dict.keys()))\n",
    "df_persons.head()\n",
    "\n",
    "#We see lot's of NaN values. So we have to take care of that. We will convert them to numpy nan and then to zero.\n",
    "df_values.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "# Count number of NaN's for columns\n",
    "print df_values.isnull().sum()\n",
    "\n",
    "# DataFrame dimension\n",
    "print df_values.shape\n",
    "\n",
    "\n",
    "df_null = df_values.replace(to_replace=np.nan, value=0)\n",
    "df_null = df_values.fillna(0).copy(deep=True)\n",
    "df_null.columns = list(df_values.columns.values)\n",
    "print df_null.isnull().sum()\n",
    "print df_null.head()\n",
    "\n",
    "df_null.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "For selecting the best features I am going to use SelectKBest method from scikit-learn. And then, I would use recursive feature selection to find a good indication of the number of relevant features and how the cross validation score varies with the increase in number of features. But before using SelectKBest, I am going to perform a few tasks. First of all I am just going to see the accuracy, precision score and the recall score of the features as they exist now using Decision Tree. The selection of Decision tree is not random. As I have already gone through one cycle, I know that Decision tree will be one of the best algorithms for fitting my model. Then I am going to perform feature engineering and create some new features and add them to the features list and take the accuracy, precision score and the recall score of the features list with these new features added to see the difference between the old features list and this new features list after newly added features. After that I plan to make it a half manual iterative process. That is, add all possible best features and then remove them one by one using the score values and human intuition. So in essence this will be a cyclic process. The recursive feature selection will help us big time to find a optimum K value to increase our model efficiency. Before building the classifier, I will also scale all features using a min-max scaler. This was vitally important, as the features had different units (e.g. # of email messages and USD) and varied significantly by several orders of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier's Result before Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: \n",
      "Accuracy: 0.837209302326\n",
      "Precision Score: 0.0\n",
      "Recall Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features_train,features_test,labels_train,labels_test = cross_validation.train_test_split(features,labels, test_size=0.3, \n",
    "                                                                                          random_state=42)\n",
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see before any feature engineering, our Decision Tree classifier is giving us an accuracy of 83.72% with Precision score and Recall Scores of 0.25 and 0.2 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Now let's add some new features of interest to the list of the features. I will make a function to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', 'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees', 'poi_ratio', 'fraction_to_poi', 'fraction_from_poi']\n"
     ]
    }
   ],
   "source": [
    "def add_poi_ratio(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email interaction with pois \"\"\"\n",
    "    fields = ['to_messages', 'from_messages',\n",
    "              'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['to_messages'] +\\\n",
    "                             person['from_messages']\n",
    "            poi_messages = person['from_poi_to_this_person'] +\\\n",
    "                           person['from_this_person_to_poi']\n",
    "            person['poi_ratio'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['poi_ratio'] = 'NaN'\n",
    "    features_list += ['poi_ratio']\n",
    "\n",
    "\n",
    "\n",
    "def add_fraction_to_poi(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email fraction_to_poi \"\"\"\n",
    "    fields = ['from_messages', 'from_this_person_to_poi']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['from_messages']\n",
    "            poi_messages =   person['from_this_person_to_poi']\n",
    "            person['fraction_to_poi'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['fraction_to_poi'] = 'NaN'\n",
    "    features_list += ['fraction_to_poi']\n",
    "\n",
    "\n",
    "def add_fraction_from_poi(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email fraction_from_poi \"\"\"\n",
    "    fields = ['to_messages', 'from_poi_to_this_person']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['to_messages']\n",
    "            poi_messages =   person['from_poi_to_this_person']\n",
    "            person['fraction_from_poi'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['fraction_from_poi'] = 'NaN'\n",
    "    features_list += ['fraction_from_poi']\n",
    "\n",
    "\n",
    "\n",
    "#Adding them to the features list\n",
    "add_poi_ratio(data_dict, my_feature_list)\n",
    "add_fraction_to_poi(data_dict, my_feature_list)\n",
    "add_fraction_from_poi(data_dict, my_feature_list)\n",
    "print my_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier's Result after Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: \n",
      "Accuracy: 0.860465116279\n",
      "Precision Score: 0.333333333333\n",
      "Recall Score: 0.2\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features_train,features_test,labels_train,labels_test = cross_validation.train_test_split(features,labels, test_size=0.3, \n",
    "                                                                                          random_state=42)\n",
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see after the feature engineering of three new features, our Decision Tree classifier is giving us an accuracy of 86.04% with both precision score and recall score of 0.400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I will use SelectKBest algorithm to rank the features in order to find the most effective features. First I put all the possible features into features_list and then started deleting them one by one using score value and human intuition. I started with all features initially. But when I ran the recursive feature selection to find a good indication of the number of relevant features and how the cross validation score varies with the increase in number of features, I saw that there was a peak at around 7. So in this 2nd cycle, we will use a value of 7 for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 best features: ['salary', 'bonus', 'total_stock_value', 'fraction_to_poi', 'exercised_stock_options', 'deferred_income', 'long_term_incentive']\n",
      "\n",
      "{'salary': 18.289684043404513, 'bonus': 20.792252047181535, 'total_stock_value': 24.182898678566879, 'fraction_to_poi': 16.409712548035799, 'exercised_stock_options': 24.815079733218194, 'deferred_income': 11.458476579280369, 'long_term_incentive': 9.9221860131898225}\n",
      "{'salary': 18.289684043404513, 'bonus': 20.792252047181535, 'total_stock_value': 24.182898678566879, 'fraction_to_poi': 16.409712548035799, 'exercised_stock_options': 24.815079733218194, 'deferred_income': 11.458476579280369, 'long_term_incentive': 9.9221860131898225}\n",
      "7 selected features: ['salary', 'bonus', 'total_stock_value', 'fraction_to_poi', 'exercised_stock_options', 'deferred_income', 'long_term_incentive']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_k_best(enron_data, features_list, k):\n",
    "    \"\"\" runs scikit-learn's SelectKBest feature selection\n",
    "        returns dict where keys=features, values=scores\n",
    "    \"\"\"\n",
    "    data = featureFormat(data_dict, features_list)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "\n",
    "    k_best = SelectKBest(k=k)\n",
    "    k_best.fit(features, labels)\n",
    "    scores = k_best.scores_\n",
    "    unsorted_pairs = zip(features_list[1:], scores)\n",
    "    sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "    k_best_features = dict(sorted_pairs[:k])\n",
    "    print \"{0} best features: {1}\\n\".format(k, k_best_features.keys())\n",
    "    print k_best_features\n",
    "    return k_best_features\n",
    "\n",
    "target_label = 'poi'\n",
    "num_features = 7 # 11 best features\n",
    "top_features = get_k_best(data_dict, features_list, num_features)\n",
    "print top_features\n",
    "my_feature_list = [target_label] + top_features.keys()\n",
    "# print my_feature_list\n",
    "\n",
    "print \"{0} selected features: {1}\\n\".format(len(my_feature_list) - 1, my_feature_list[1:])\n",
    "\n",
    "features_list = my_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity of SelectKBest\n",
    "\n",
    "Using these sets of features gave me an accuracy of around 71.43% in the first cycle, and the precision and the recall score remained very low(0.2 and 0.333 respectively) which are the more vital metrices for this specific project even more than the accuracy. This is because in this specific dataset, only 18 POIs are present. Originally there were 35 POIs. But for some reason half of them is not present in this dataset. So accuracy cannot be depended on very much for this dataset and thus we have to depend heavily on the precision and the recall score.\n",
    "\n",
    "So after much manual intervention and going back and forth, I selected the following features to be the final features as these are informations directly related to the POIs and hence not very open to interpretation even to machines. So a high value of fraction_from_poi may indicate that the person receiving those emails may be a POI himself or even in the executive board. Same logic goes for fraction_to_poi and shared_receipt_with_poi. These features were not selected at random but after extensive manual testing.\n",
    "\n",
    "1. fraction_from_poi\n",
    "2. fraction_to_poi\n",
    "3. shared_receipt_with_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\"poi\", \"fraction_from_poi\", \"fraction_to_poi\", \"shared_receipt_with_poi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features did I end up using in your POI identifier, and what selection process did I use to pick them? Did I have to do any scaling? Why or why not?\n",
    "\n",
    "In this project, first I used scikit-learn's SelectKBest module to get the 7 best features among the 21 features present. This was because in the recursive feature selection, I saw a peak at around 7 for the features vs cross validation score. But this had to be a half manual iterative process as the dataset is very skewed towards non POIs and only 18 POIs were there in the dataset. So when I was using the 7 features suggested by SelectKBest algorithm, I was getting an accuracy of only ~72% with very low precision and recall score (0.2 and 0.333 respectively). In the below table you can see the top 7 features along with their scores. The K-best approach is an automated univariate feature selection algorithm, and in using it, I was concerned with the lack of email features in the resulting dataset. Thus, I engineered three features, poi_ratio, fraction_to_poi and fraction_from_poi which were the proportion of email interaction with POIs, proportion of email fraction to POIs and proportion of email fraction from POIs. So here we mutate our original data dictionary and add these new features to the features' list. The scores of the 7 best features selected by K-best approach is given below. Apart from these 7 features, I also added 3 more features regarding emails: ** 'poi_ratio', 'fraction_to_poi' and 'fraction_from_poi' ** .\n",
    "\n",
    "1. exercised_stock_options: 24.815079733218194\n",
    "2. total_stock_value: 24.182898678566879\n",
    "3. bonus: 20.792252047181535\n",
    "4. salary: 18.289684043404513\n",
    "5. fraction_to_poi: 16.409712548035799\n",
    "6. deferred_income: 11.458476579280369\n",
    "7. long_term_incentive: 9.9221860131898225\n",
    "\n",
    "After much iterative manual testing with different combinations of the features and trying out by deleting them one at a time, I finally came up with these 4 features to be used as my final features list:\n",
    "\n",
    "** 1. ** fraction_from_poi\n",
    "\n",
    "** 2. ** fraction_to_poi\n",
    "\n",
    "** 3. ** shared_receipt_with_poi\n",
    "\n",
    "\n",
    "Before training the machine learning algorithm classifiers, I scaled all features using a min-max scaler. This was vitally important, as the features had different units and varied significantly by several orders of magnitude. Feature-scaling ensured that for the applicable classifiers, the features would be weighted evenly. Only after this step, I split my data into training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and labels from dataset for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features by MinMaxScaler from Sklearn preprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train data(70%) and test data(30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train,features_test,labels_train,labels_test = cross_validation.train_test_split(features,labels, test_size=0.3, \n",
    "                                                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different Machine Learning Classifiers\n",
    "\n",
    "We will iterate through variety of classifiers to see which one's prediction is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: \n",
      "Accuracy: 0.961538461538\n",
      "Precision Score: 1.0\n",
      "Recall Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier: \n",
      "Accuracy: 0.923076923077\n",
      "Precision Score: 0.0\n",
      "Recall Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"Naive Bayes Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier: \n",
      "Accuracy: 0.961538461538\n",
      "Precision Score: 1.0\n",
      "Recall Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"Adaboost Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Vector Machine (rbf) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier: \n",
      "Accuracy: 0.923076923077\n",
      "Precision Score: 0.0\n",
      "Recall Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma=3, C=2)\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"SVM Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier: \n",
      "Accuracy: 0.846153846154\n",
      "Precision Score: 0.0\n",
      "Recall Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test,pred)\n",
    "print(\"kNN Classifier: \")\n",
    "print \"Accuracy: \" + str(accuracy)\n",
    "print \"Precision Score: \" + str(precision_score(labels_test,pred))\n",
    "print \"Recall Score: \" + str(recall_score(labels_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What algorithm did I end up using? What other one(s) did I try? How did model performance differ between algorithms?\n",
    "\n",
    "I used Decision Tree Classifier to predict the possible POIs in the dataset. The main motivation for me behind using this classifier was that the Nonlinear relationships between parameters do not affect tree performance and Decision trees implicitly perform variable screening or feature selection. I also noticed that this was one of the classifiers which was giving one of the highest accuracies. Apart from Decision trees, I also tried fitting the train data and predict the test data with Naive Bayes, Adaboost, K Nearest Neighbours and Standard Vector Machine classifiers. Adaboost gave almost as high precision metrices as decision trees. Naive Bayes and SVM also gave higher accuracy scores around 92-93% but the precision and the recall score of SVM was zero. With Decision trees, at this point I was getting an accuracy score around 96.15% with a precision score of 1 and recall score of 0.500. Given below are the precision metrices for all the algorithms I tried.\n",
    "\n",
    "** 1. Decision Tree **\n",
    " \n",
    " a) Accuracy - 96.153%\n",
    "  \n",
    " b) Precision Score - 1\n",
    "  \n",
    " c) Recall Score - 0.500\n",
    "  \n",
    "   \n",
    "** 2. Naive Bayes **\n",
    "\n",
    " a) Accuracy: 92.31%\n",
    "  \n",
    " b) Precision Score: 0\n",
    "  \n",
    " c) Recall Score: 0\n",
    " \n",
    "** 4. Adaboost **\n",
    "\n",
    " a) Accuracy: 96.153%\n",
    " \n",
    " b) Precision Score: 1\n",
    " \n",
    " c) Recall Score: 0.5\n",
    " \n",
    "** 5. Standard Vector Machine **\n",
    "\n",
    " a) Accuracy: 92.31%\n",
    " \n",
    " b) Precision Score: 0\n",
    " \n",
    " c) Recall Score: 0\n",
    " \n",
    "** 6. K nearest neighbours **\n",
    "\n",
    " a) Accuracy: 84.62%\n",
    " \n",
    " b) Precision Score: 0\n",
    " \n",
    " c) Recall Score: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does it mean to tune the parameters of an algorithm, and what can happen if I dont do this well?  How did I tune the parameters of your particular algorithm? What parameters did I tune?\n",
    "\n",
    "Parameter tuning for any algorithm in Machine Learning is a vital step. Our goal, is usually to set the parameters for the algorithm used to get optimal values that enable us to complete a learning task in the best way possible. Thus, tuning an algorithm or machine learning technique, can be simply thought of as process which one goes through in which they optimize the parameters that impact the model in order to enable the algorithm to perform the best (once, of course we have defined what \"best\" actual is).\n",
    "\n",
    "With our dataset accuracy is not quite meaningful because of the disproportion among classes. So here, we are more interested in the precision score and the recall score metrices. Before tuning my algorithm, the values precision score was 1 and the recall score was 0.500 with an accuracy of 96.15%. Maybe this high value was caused by some overfitting. I tuned my Decision Tree Classifier model with GridSearchCV and validated the using Stratified Shuffle Split and Cross Validation with my customized scoring function to put a threshold for both precision_score and the recall_score. The parameters which I tuned were max_depth, min_samples_split, min_samples_leaf and criterion. The final accuracy I got after tuning my model ranged between 87-89% with a precision score around 0.433 and the recall score of 0.822."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.StratifiedShuffleSplit(labels, n_iter=10)\n",
    "\n",
    "\n",
    "def scoring(estimator, features_test, labels_test):\n",
    "    labels_pred = estimator.predict(features_test)\n",
    "    p = precision_score(labels_test, labels_pred, average='micro')\n",
    "    r = recall_score(labels_test, labels_pred, average='micro')\n",
    "    if p > 0.3 and r > 0.3:\n",
    "        return f1_score(labels_test, labels_pred, average='macro')\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 3\n",
      "[ True  True  True]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEbCAYAAADJWrOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZfL/e6lvxtMLE8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc3e0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "rfecv = RFECV(estimator=clf, step=1, cv=StratifiedKFold(labels, 50),\n",
    "          scoring='precision')\n",
    "rfecv.fit(features, labels)\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print rfecv.support_\n",
    "features=features[:,rfecv.support_]\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=8,\n",
      "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.887857142857\n",
      "Processing time: 112.183 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "parameters = {'max_depth': [1, 2, 3, 4, 5, 6, 8, 9, 10], 'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8], 'criterion': ('gini', 'entropy')}\n",
    "\n",
    "decTree_clf = DecisionTreeClassifier()\n",
    "decTreeclf = grid_search.GridSearchCV(decTree_clf, parameters, scoring=scoring, cv=cv)\n",
    "\n",
    "decTreeclf.fit(features, labels)\n",
    "print decTreeclf.best_estimator_\n",
    "print decTreeclf.best_score_\n",
    "print 'Processing time:', round(time() - t0, 3), 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is validation, and whats a classic mistake you can make if I do it wrong? How did I validate my analysis?\n",
    "\n",
    "In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived. The main purpose of using the testing data set is to test the generalization ability of a trained model. Validation is performed to ensure that a machine learning algorithm generalizes well. A classic mistake is over-fitting, where the model is trained and performs very well on the training dataset, but markedly worse on the cross-validation and test datasets. I utilized two methods for validating the analysis:\n",
    "\n",
    "1. ** StratifiedShuffleSplit, folds = 1000 : ** The main reason why I used Startified Shuffle Split as a validation method was that the dataset was small and skewed towards non-POI. I needed a technique that accounts for that. Otherwise the risk is that in the validation phase, we would not be able to assess the real potential of our algorithm in terms of performance metrics. The chance of randomly splitting skewed and non representative validation sub-sets could be high, therefore the need to use stratification (preservation of the percentage of samples for each class) to achieve robustness in a dataset with the aforementioned limitations. I took the average precision an recall score of 1000 randomized trials with the help of test_classifier function. This data was subset into training and testing set in a 3:1 ratio.\n",
    "\n",
    "2. ** Cross Validation: ** Cross Validation is a technique which involves reserving a particular sample of a data set on which you do not train the model. Later, you test the model on this sample before finalizing the model. Here I did a cross validation on the data by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time). I used 'accuracy' as a scorer object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=8,\n",
      "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.86056\tPrecision: 0.43286\tRecall: 0.82200\tF1: 0.56709\tF2: 0.69673\n",
      "\tTotal predictions: 9000\tTrue positives:  822\tFalse positives: 1077\tFalse negatives:  178\tTrue negatives: 6923\n",
      "\n",
      "Processing time: 2.276 s\n"
     ]
    }
   ],
   "source": [
    "##DecisionTreeClassifier Validation 1 (StratifiedShuffleSplit, folds = 1000)\n",
    "from tester import test_classifier\n",
    "t0 = time()\n",
    "decTree_best_clf = decTreeclf.best_estimator_\n",
    "test_classifier(decTree_best_clf, my_dataset, features_list)\n",
    "print 'Processing time:', round(time() - t0, 3), 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and Deviation: (0.84738562091503267, 0.10525920072782949)\n",
      "Processing time: 0.052 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=8,\n",
      "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.86056\tPrecision: 0.43286\tRecall: 0.82200\tF1: 0.56709\tF2: 0.69673\n",
      "\tTotal predictions: 9000\tTrue positives:  822\tFalse positives: 1077\tFalse negatives:  178\tTrue negatives: 6923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##DecisionTreeClassifier Validation 2  (Cross validation)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "t0 = time()\n",
    "decTree_best_clf = decTreeclf.best_estimator_\n",
    "scores = cross_val_score(decTree_best_clf, features, labels, cv=5,scoring = 'accuracy')\n",
    "print(\"Accuracy and Deviation: \" + str((scores.mean(), scores.std() * 2)))\n",
    "print 'Processing time:', round(time() - t0, 3), 's'\n",
    "test_classifier(decTree_best_clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give at least 2 evaluation metrics and the average performance for each of them.  Explain an interpretation of my metrics that says something human-understandable about my algorithms performance.\n",
    "\n",
    "The main evaluation metrics utilized were precision and recall. Precision captures the ratio of true positives to the records that are actually POIs, essentially describing how often 'false alarms' are (not) raised. Recall captures the ratio of true positives to the records flagged as POIs, which describes sensitivity. For the Decision tree algorithm which I used, following were the evaluation metrices for the two validations:\n",
    "\n",
    "** 1. StratifiedShuffleSplit **\n",
    "\n",
    " a) Precision: 0.50829\t\n",
    " \n",
    " b) Recall: 0.82200\n",
    "   \n",
    "** 2. Cross Validation **\n",
    "\n",
    " a) Precision: 0.50292\n",
    " \n",
    " b) Recall: 0.82200\n",
    "\n",
    "Both validations performed quite well given the fact that this dataset didn't contain plethora of data (very few POIs) and the data was noisy too. The recall score is very high. This is actually a good thing. The ratio of the false positives to true positives is much higher than the ratio of false negatives to true negatives. This is actually good for us because we would rather mark a person as POI who in reality is not a POI than not able to catch the Real POIs and marking them as False POIs. My argument here is even though we mark someone as a POI wrongly, he/she will still get through unscathed after investigation. But on the other hand, if we miss someone who is indeed guilty, then that person is just not facing the justice as he/she should have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "So we see by applying Stratified Shuffle Split to our Decision Tree Classifier, we are able to improve the performance metrices of our classifier. This dataset is a very sparse dataset where accuracy(almost 89% in our case) is not a good metrics given the fact it is very skewed towards non POIs. We only have 18 POIs in the dataset. Even though originally we had 36 POIs, somehow half of them are not present in this dataset. We have a high recall score(0.822) which is a good thing given how sparse this dataset is and where accuracy is not a good metrics to perform model quality. We also see that ratio of the false positives to true positives is much higher than the ratio of false negatives to true negatives. This is actually good for us because we would rather mark a person as POI who in reality is not a POI than not able to catch the Real POIs and marking them as False POIs. My argument here is even though we mark someone as a POI wrongly, he/she will still get through unscathed after investigation. But on the other hand, if we miss someone who is indeed guilty, then that person is just not facing the justice as he/she should have. \n",
    "\n",
    "These numbers are quite good but still we can improve the accuracy of the model. One of the possible ways is to dig into the actual email messages more. Then we can find a pattern of emails to/from a specific point instead of to/from POIs. We can also do text mining to make some vocabulary pattern emerge from this huge chunks of emails to get more behavioural patterns of the POIs. As we found out that the POI data was incomplete in our dataset, the next realistic thing to try might be to extract more data from the emails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
